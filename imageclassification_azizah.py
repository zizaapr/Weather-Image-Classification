# -*- coding: utf-8 -*-
"""ImageClassification_Azizah.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fi84kkKZtbdpkvPm6glWavD17mdK9ooh

# Proyek Klasifikasi Gambar: [Weather Image Dataset]
- **Nama:** Azizah Nur Apriliani
- **Email:** azizahprln@gmail.com
- **ID Dicoding:** M891D5X0328

## Import Semua Packages/Library yang Digunakan
"""

!pip install tensorflowjs

import zipfile
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflowjs as tfjs
import random
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers

"""## Data Preparation

### Data Loading
"""

# Hubungkan Google Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# lokasi file ZIP dan folder ekstraksi
file_zip = '/content/drive/MyDrive/klasifikasi/Weather-Image-Dataset.zip'
output_dir = '/content/WeatherData'

# Ekstraksi file ZIP
with zipfile.ZipFile(file_zip, mode='r') as archive:
    archive.extractall(path=output_dir)

# Tampilkan daftar isi folder hasil ekstraksi
print("Isi folder hasil ekstraksi:")
print(os.listdir(output_dir))

"""### Data Preprocessing

#### Split Dataset
"""

base_dir = "/content/WeatherData"

datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

train_gen = datagen.flow_from_directory(
    base_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='training',
    seed=123
)

val_test_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.5)

val_gen = val_test_datagen.flow_from_directory(
    base_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='training',
    seed=123
)

test_gen = val_test_datagen.flow_from_directory(
    base_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='validation',
    seed=123
)

"""## Modelling"""

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(train_gen.num_classes, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

callbacks = [
    EarlyStopping(
        monitor='val_loss',
        patience=3,
        restore_best_weights=True
    ),

    ModelCheckpoint(
        filepath='/content/best_model.keras',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    ),

    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.2,
        patience=2,
        min_lr=1e-5,
        verbose=1
    )
]

history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=30,
    callbacks=callbacks
)

"""## Evaluasi dan Visualisasi"""

# load model terbaik yang sudah disimpan sebelumnya
best_model = load_model('best_model.keras')

train_loss, train_acc = best_model.evaluate(train_gen, verbose=0)
test_loss, test_acc = best_model.evaluate(test_gen, verbose=0)

print(f"Train Accuracy: {train_acc*100:.2f}%")
print(f"Test Accuracy: {test_acc*100:.2f}%")

# Visualisasi hasil pelatihan model
fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))

# Grafik Akurasi
axes[0].plot(history.history['accuracy'], color='green', linestyle='-', marker='o', label='Akurasi Training')
axes[0].plot(history.history['val_accuracy'], color='orange', linestyle='--', marker='x', label='Akurasi Validasi')
axes[0].set_title('Perbandingan Akurasi Training & Validasi')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Akurasi')
axes[0].grid(True)
axes[0].legend()

# Grafik Loss
axes[1].plot(history.history['loss'], color='red', linestyle='-', marker='o', label='Loss Training')
axes[1].plot(history.history['val_loss'], color='blue', linestyle='--', marker='x', label='Loss Validasi')
axes[1].set_title('Perbandingan Loss Training & Validasi')
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('Loss')
axes[1].grid(True)
axes[1].legend()

plt.suptitle('Grafik Akurasi dan Loss Selama Training', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

"""## Konversi Model"""

# Direktori menyimpan model
saved_model_dir = '/content/saved_model_weather'
os.makedirs(saved_model_dir, exist_ok=True)

# Export SavedModel
model.export(saved_model_dir)

# Save ke TFLite
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()

with open('/content/weather_model.tflite', 'wb') as f:
    f.write(tflite_model)

# Save ke TFJS
tfjs_target_dir = '/content/tfjs_model_weather'
os.makedirs(tfjs_target_dir, exist_ok=True)
tfjs.converters.save_keras_model(model, tfjs_target_dir)

print("Model saved successfully in SavedModel, TFLite, and TFJS formats.")

"""## Inference (Optional)"""

sample_img, label = next(test_gen)
pred = model.predict(sample_img)

class_indices = test_gen.class_indices
idx_to_class = {v: k for k, v in class_indices.items()}

predicted_classes = np.argmax(pred, axis=1)

chosen_idx = random.randint(0, len(predicted_classes) - 1)

# Tampilkan gambar
plt.figure(figsize=(5, 5))
plt.imshow(sample_img[chosen_idx])
plt.axis('off')
pred_label = idx_to_class[predicted_classes[chosen_idx]]
plt.title(pred_label, fontsize=12)
plt.show()

!pip freeze > requirements.txt